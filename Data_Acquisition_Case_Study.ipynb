{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aRvzWzbhcnp"
   },
   "source": [
    "#Data Acquisition Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "734JDyUNq8fH"
   },
   "source": [
    "## Q1. Write Python code to create a new file named \"sample_data.txt\" in your documents folder and write the following content to it\n",
    "\n",
    "ICTAK\n",
    "\n",
    "Thejaswini,\n",
    "\n",
    "Technopark Rd,\n",
    "\n",
    "Technopark Campus,\n",
    "\n",
    "Thiruvananthapuram,\n",
    "\n",
    "Kerala 695581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ieKhqBr-nl7s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'sample_data.txt' has been created in C:\\DSA ICTKERALA.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "content = \"\"\"ICTAK\n",
    "Thejaswini,\n",
    "Technopark Rd,\n",
    "Technopark Campus,\n",
    "Thiruvananthapuram,\n",
    "Kerala 695581\"\"\"\n",
    "documents_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\")\n",
    "file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(content)\n",
    "\n",
    "print(f\"File 'sample_data.txt' has been created in {documents_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ6hQOJpimNv"
   },
   "source": [
    "## Q2. Write Python code to read and print the contents in \"sample_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vRnilPQgnrPG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of 'sample_data.txt':\n",
      "ICTAK\n",
      "Thejaswini,\n",
      "Technopark Rd,\n",
      "Technopark Campus,\n",
      "Thiruvananthapuram,\n",
      "Kerala 695581\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "documents_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\")\n",
    "file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    print(\"Contents of 'sample_data.txt':\")\n",
    "    print(content)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file 'sample_data.txt' does not exist in {documents_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aHquDcErda-"
   },
   "source": [
    "## Q3. Write Python code to check if \"sample_data.txt\" exists in documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vY5TEsxunsKh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'sample_data.txt' exists in C:\\DSA ICTKERALA.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "documents_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\")\n",
    "file_path = os.path.join(documents_folder, \"sample_data.txt\")\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file 'sample_data.txt' exists in {documents_folder}.\")\n",
    "else:\n",
    "    print(f\"The file 'sample_data.txt' does not exist in {documents_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCWITkmopblI"
   },
   "source": [
    "## Q4: Save the following dataframe content to a CSV file (data.csv) in your downloads folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3THwBOGpP9F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Joc7XafnntaG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has been saved to C:\\DSA ICTKERALA\\data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = {\"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "downloads_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\")\n",
    "file_path = os.path.join(downloads_folder, \"data.csv\")\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Dataframe has been saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF0nJjGElq0A"
   },
   "source": [
    "## Q5: Save the above dataframe content to an Excel (data.xlsx, sheet name: Sheet1) file in your documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtOFb7ZJnu1m"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = {\"Id\": [1, 2, 3],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"Subject\": [\"Science\", \"Maths\", \"History\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "documents_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\")\n",
    "file_path = os.path.join(documents_folder, \"data.xlsx\")\n",
    "\n",
    "df.to_excel(file_path, index=False, sheet_name=\"Sheet1\")\n",
    "\n",
    "print(f\"Dataframe has been saved to {file_path} with sheet name 'Sheet1'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amF6kxMQmdgF"
   },
   "source": [
    "## Q6. Write code to get the list of files in your Downloads folder and save it to a CSV file name \"download_list.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nVP86z3dnvwz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of files has been saved to C:\\DSA ICTKERALA\\download_list.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "downloads_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\")\n",
    "\n",
    "files = os.listdir(downloads_folder)\n",
    "\n",
    "df = pd.DataFrame({\"File Name\": files})\n",
    "\n",
    "\n",
    "csv_file_path = os.path.join(downloads_folder, \"download_list.csv\")\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"List of files has been saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vR7I4R5bnV2w"
   },
   "source": [
    "## Q7. Write Python code to save the contents of the given random_array variable as a numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHXYRxnDnJzA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_array = np.random.rand(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ihhSKJF9n3NP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array has been saved to 'random_array.npy'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_array = np.random.rand(10, 10)\n",
    "np.save(\"random_array.npy\", random_array)\n",
    "print(\"The array has been saved to 'random_array.npy'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7XfHgGAzNIl"
   },
   "source": [
    "## Q8. Write python code to save the contents of the above numpy file as text file named \"random.txt\" with a delimitter of \";\" to Documents folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Du3LRbaKbpeg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array has been saved as 'random.txt' in the Documents folder.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "array = np.load(\"random_array.npy\")\n",
    "documents_folder = os.path.expanduser(\"C:\\\\DSA ICTKERALA\") \n",
    "text_file_path = os.path.join(documents_folder, \"random.txt\")\n",
    "np.savetxt(text_file_path, array, delimiter=\";\")\n",
    "print(f\"The array has been saved as 'random.txt' in the Documents folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJSaX0Rg151y"
   },
   "source": [
    "## Download and analyze Bike Sharing Dataset (hour.csv) for UCI Irvin Repository (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wt4mxq32U6H"
   },
   "source": [
    "## Q9. What is the size of the dataset? (Number of rows and columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Pj0I0JhF2EEg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 17379\n",
      "Number of columns: 17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\") \n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbDnC_i438m8"
   },
   "source": [
    "## Q10. What are the data types of each column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_YJIqJEZ3-DC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant         int64\n",
      "dteday         object\n",
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "hr              int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "casual          int64\n",
      "registered      int64\n",
      "cnt             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "print(data.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi0jHMq-3_NI"
   },
   "source": [
    "## Q11. Are there any missing values in the dataset? If so, which columns have missing values and how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mct7F2M-3-kQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values and their counts:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Columns with missing values and their counts:\")\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew__56Iq4BMK"
   },
   "source": [
    "## Q.12. For the windspeed column, calculate the mean, median, and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ucijLTNA4Clr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of windspeed: 0.1900976063064618\n",
      "Median of windspeed: 0.194\n",
      "Standard Deviation of windspeed: 0.12234022857279049\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "mean_windspeed = data['windspeed'].mean()\n",
    "median_windspeed = data['windspeed'].median()\n",
    "std_windspeed = data['windspeed'].std()\n",
    "print(f\"Mean of windspeed: {mean_windspeed}\")\n",
    "print(f\"Median of windspeed: {median_windspeed}\")\n",
    "print(f\"Standard Deviation of windspeed: {std_windspeed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dHaYtuP4C78"
   },
   "source": [
    "## Q13. Identify any potential outliers in a numerical column of your choice. Explain your approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nVkU-okb4EiU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in 'temp': 0\n",
      "Outliers:\n",
      "Empty DataFrame\n",
      "Columns: [temp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "column = 'temp'\n",
    "Q1 = data[column].quantile(0.25)  \n",
    "Q3 = data[column].quantile(0.75)  \n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "print(f\"Number of outliers in '{column}': {len(outliers)}\")\n",
    "print(f\"Outliers:\\n{outliers[[column]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14sUq8ZF4E88"
   },
   "source": [
    "## Q.14 Find the correlation between numerical columns and discuss any interesting relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jnAOuuwt4Hmb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix:\n",
      "             instant    season        yr      mnth        hr   holiday  \\\n",
      "instant     1.000000  0.404046  0.866014  0.489164 -0.004775  0.014723   \n",
      "season      0.404046  1.000000 -0.010742  0.830386 -0.006117 -0.009585   \n",
      "yr          0.866014 -0.010742  1.000000 -0.010473 -0.003867  0.006692   \n",
      "mnth        0.489164  0.830386 -0.010473  1.000000 -0.005772  0.018430   \n",
      "hr         -0.004775 -0.006117 -0.003867 -0.005772  1.000000  0.000479   \n",
      "holiday     0.014723 -0.009585  0.006692  0.018430  0.000479  1.000000   \n",
      "weekday     0.001357 -0.002335 -0.004485  0.010400 -0.003498 -0.102088   \n",
      "workingday -0.003416  0.013743 -0.002196 -0.003477  0.002285 -0.252471   \n",
      "weathersit -0.014198 -0.014524 -0.019157  0.005400 -0.020203 -0.017036   \n",
      "temp        0.136178  0.312025  0.040913  0.201691  0.137603 -0.027340   \n",
      "atemp       0.137615  0.319380  0.039222  0.208096  0.133750 -0.030973   \n",
      "hum         0.009577  0.150625 -0.083546  0.164411 -0.276498 -0.010588   \n",
      "windspeed  -0.074505 -0.149773 -0.008740 -0.135386  0.137252  0.003988   \n",
      "casual      0.158295  0.120206  0.142779  0.068457  0.301202  0.031564   \n",
      "registered  0.282046  0.174226  0.253684  0.122273  0.374141 -0.047345   \n",
      "cnt         0.278379  0.178056  0.250495  0.120638  0.394071 -0.030927   \n",
      "\n",
      "             weekday  workingday  weathersit      temp     atemp       hum  \\\n",
      "instant     0.001357   -0.003416   -0.014198  0.136178  0.137615  0.009577   \n",
      "season     -0.002335    0.013743   -0.014524  0.312025  0.319380  0.150625   \n",
      "yr         -0.004485   -0.002196   -0.019157  0.040913  0.039222 -0.083546   \n",
      "mnth        0.010400   -0.003477    0.005400  0.201691  0.208096  0.164411   \n",
      "hr         -0.003498    0.002285   -0.020203  0.137603  0.133750 -0.276498   \n",
      "holiday    -0.102088   -0.252471   -0.017036 -0.027340 -0.030973 -0.010588   \n",
      "weekday     1.000000    0.035955    0.003311 -0.001795 -0.008821 -0.037158   \n",
      "workingday  0.035955    1.000000    0.044672  0.055390  0.054667  0.015688   \n",
      "weathersit  0.003311    0.044672    1.000000 -0.102640 -0.105563  0.418130   \n",
      "temp       -0.001795    0.055390   -0.102640  1.000000  0.987672 -0.069881   \n",
      "atemp      -0.008821    0.054667   -0.105563  0.987672  1.000000 -0.051918   \n",
      "hum        -0.037158    0.015688    0.418130 -0.069881 -0.051918  1.000000   \n",
      "windspeed   0.011502   -0.011830    0.026226 -0.023125 -0.062336 -0.290105   \n",
      "casual      0.032721   -0.300942   -0.152628  0.459616  0.454080 -0.347028   \n",
      "registered  0.021578    0.134326   -0.120966  0.335361  0.332559 -0.273933   \n",
      "cnt         0.026900    0.030284   -0.142426  0.404772  0.400929 -0.322911   \n",
      "\n",
      "            windspeed    casual  registered       cnt  \n",
      "instant     -0.074505  0.158295    0.282046  0.278379  \n",
      "season      -0.149773  0.120206    0.174226  0.178056  \n",
      "yr          -0.008740  0.142779    0.253684  0.250495  \n",
      "mnth        -0.135386  0.068457    0.122273  0.120638  \n",
      "hr           0.137252  0.301202    0.374141  0.394071  \n",
      "holiday      0.003988  0.031564   -0.047345 -0.030927  \n",
      "weekday      0.011502  0.032721    0.021578  0.026900  \n",
      "workingday  -0.011830 -0.300942    0.134326  0.030284  \n",
      "weathersit   0.026226 -0.152628   -0.120966 -0.142426  \n",
      "temp        -0.023125  0.459616    0.335361  0.404772  \n",
      "atemp       -0.062336  0.454080    0.332559  0.400929  \n",
      "hum         -0.290105 -0.347028   -0.273933 -0.322911  \n",
      "windspeed    1.000000  0.090287    0.082321  0.093234  \n",
      "casual       0.090287  1.000000    0.506618  0.694564  \n",
      "registered   0.082321  0.506618    1.000000  0.972151  \n",
      "cnt          0.093234  0.694564    0.972151  1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "numerical_data = data.select_dtypes(include=['number'])\n",
    "correlation_matrix = numerical_data.corr()\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru-xlbd44IAY"
   },
   "source": [
    "## Q.15 Based on your analysis, provide a brief summary of any insights or patterns you discovered in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15NUIdxK4I03"
   },
   "outputs": [],
   "source": [
    "Seasonal and Weather Impact:\n",
    "The number of bike rentals (cnt) could show a clear trend across seasons (season column), with higher rentals during warmer months.\n",
    "Weather conditions (weathersit, temp, atemp, windspeed, etc.) might significantly influence usage. For instance, rentals could drop \n",
    "on days with high wind speeds or during adverse weather conditions.\n",
    "    \n",
    "Time-of-Day Patterns:\n",
    "If you examine the hour column, it may reveal peak rental hours. Typically, these coincide with commuting times, such as early mornings and evenings.\n",
    "\n",
    "Correlation Between Features:\n",
    "Strong positive correlation between temp and atemp indicates consistency in these measurements.\n",
    "Usage patterns might correlate with days of the week (weekday), showing variations between workdays and weekends.\n",
    "\n",
    "Impact of Holidays:\n",
    "Analyzing the holiday column could reveal whether rentals increase or decrease on holidays compared to regular days.\n",
    "These are general trends that you might discover while working with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMGro15Q5WhF"
   },
   "source": [
    "## Q.16 In which season (Spring, Summer, Fall, Winter) people rented bikes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KhlVV_bK5jxm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal bike rentals:\n",
      "season\n",
      "Fall      1061129\n",
      "Spring     471348\n",
      "Summer     918589\n",
      "Winter     841613\n",
      "Name: cnt, dtype: int64\n",
      "The season with the most rentals is Fall with 1061129 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "season_mapping = {1: \"Spring\", 2: \"Summer\", 3: \"Fall\", 4: \"Winter\"}\n",
    "data['season'] = data['season'].map(season_mapping)\n",
    "season_rentals = data.groupby('season')['cnt'].sum()\n",
    "most_rented_season = season_rentals.idxmax()\n",
    "most_rented_count = season_rentals.max()\n",
    "print(\"Seasonal bike rentals:\")\n",
    "print(season_rentals)\n",
    "print(f\"The season with the most rentals is {most_rented_season} with {most_rented_count} rentals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eudb_1Lb5sVc"
   },
   "source": [
    "## Q.17 What is the peak hour in which bike rents the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "p0xSgv8g50yt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
      "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
      "       'casual', 'registered', 'cnt'],\n",
      "      dtype='object')\n",
      "Hourly bike rentals:\n",
      "hr\n",
      "0      39130\n",
      "1      24164\n",
      "2      16352\n",
      "3       8174\n",
      "4       4428\n",
      "5      14261\n",
      "6      55132\n",
      "7     154171\n",
      "8     261001\n",
      "9     159438\n",
      "10    126257\n",
      "11    151320\n",
      "12    184414\n",
      "13    184919\n",
      "14    175652\n",
      "15    183149\n",
      "16    227748\n",
      "17    336860\n",
      "18    309772\n",
      "19    226789\n",
      "20    164550\n",
      "21    125445\n",
      "22     95612\n",
      "23     63941\n",
      "Name: cnt, dtype: int64\n",
      "The peak hour is 17:00 with 336860 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "print(data.columns)\n",
    "hourly_rentals = data.groupby('hr')['cnt'].sum() \n",
    "peak_hour = hourly_rentals.idxmax()\n",
    "peak_rentals = hourly_rentals.max()\n",
    "print(\"Hourly bike rentals:\")\n",
    "print(hourly_rentals)\n",
    "print(f\"The peak hour is {peak_hour}:00 with {peak_rentals} rentals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7rArqGQ6ji4"
   },
   "source": [
    "## Q.18 In which day of a week bikes rents out most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6GPCbpsx6oYE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike rentals by day of the week:\n",
      "weekday\n",
      "Friday       487790\n",
      "Thursday     485395\n",
      "Saturday     477807\n",
      "Wednesday    473048\n",
      "Tuesday      469109\n",
      "Monday       455503\n",
      "Sunday       444027\n",
      "Name: cnt, dtype: int64\n",
      "The day with the most rentals is Friday with 487790 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\" \n",
    "data = pd.read_csv(file_path)\n",
    "weekday_mapping = {\n",
    "    0: \"Sunday\",\n",
    "    1: \"Monday\",\n",
    "    2: \"Tuesday\",\n",
    "    3: \"Wednesday\",\n",
    "    4: \"Thursday\",\n",
    "    5: \"Friday\",\n",
    "    6: \"Saturday\"\n",
    "}\n",
    "data['weekday'] = data['weekday'].map(weekday_mapping)\n",
    "weekday_rentals = data.groupby('weekday')['cnt'].sum()\n",
    "weekday_rentals = weekday_rentals.sort_values(ascending=False)\n",
    "most_rented_day = weekday_rentals.idxmax()\n",
    "most_rented_count = weekday_rentals.max()\n",
    "\n",
    "print(\"Bike rentals by day of the week:\")\n",
    "print(weekday_rentals)\n",
    "print(f\"The day with the most rentals is {most_rented_day} with {most_rented_count} rentals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFO_Twk66qw-"
   },
   "source": [
    "## Q.19 In which hour Casual users rents bikes the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "59CHoEUt66GR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly rentals for Casual users:\n",
      "hr\n",
      "0      7375\n",
      "1      4709\n",
      "2      3412\n",
      "3      1893\n",
      "4       874\n",
      "5      1012\n",
      "6      3017\n",
      "7      8037\n",
      "8     15761\n",
      "9     22458\n",
      "10    33789\n",
      "11    43286\n",
      "12    49718\n",
      "13    52713\n",
      "14    55089\n",
      "15    54606\n",
      "16    53834\n",
      "17    54220\n",
      "18    44496\n",
      "19    35505\n",
      "20    26378\n",
      "21    20570\n",
      "22    16200\n",
      "23    11065\n",
      "Name: casual, dtype: int64\n",
      "The peak hour for Casual users is 14:00 with 55089 rentals.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "hourly_casual_rentals = data.groupby('hr')['casual'].sum()\n",
    "peak_hour_casual = hourly_casual_rentals.idxmax()\n",
    "peak_rentals_casual = hourly_casual_rentals.max()\n",
    "\n",
    "print(\"Hourly rentals for Casual users:\")\n",
    "print(hourly_casual_rentals)\n",
    "print(f\"The peak hour for Casual users is {peak_hour_casual}:00 with {peak_rentals_casual} rentals.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtvgNN-U69rh"
   },
   "source": [
    "## Q.20 What is the maximum temperature observed in each of the seasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "U_NwDHv57tLT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum temperature observed in each season:\n",
      "season\n",
      "Fall      1.00\n",
      "Spring    0.72\n",
      "Summer    0.94\n",
      "Winter    0.76\n",
      "Name: temp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\DSA ICTKERALA\\bike+sharing+dataset\\hour.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "season_mapping = {1: \"Spring\", 2: \"Summer\", 3: \"Fall\", 4: \"Winter\"}\n",
    "data['season'] = data['season'].map(season_mapping)\n",
    "max_temp_per_season = data.groupby('season')['temp'].max()\n",
    "print(\"Maximum temperature observed in each season:\")\n",
    "print(max_temp_per_season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
